---
bibliography: bio.bib
csl: harvard-cite-them-right.csl
title: Group Name's Group Project
execute:
  echo: false
  freeze: true
format:
  html:
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    mainfont: Spectral
    sansfont: "Roboto Flex"
    monofont: InputMonoCondensed
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

## Declaration of Authorship {.unnumbered .unlisted}

We, JueLin Liu, Yingxi Zhou, Yale Lu, Yuanqing Zhang, Kun Li , pledge our honour that the work presented in this assessment is our own. Where information has been derived from other sources, we confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used we confirm that we have made its contribution to the final submission clear.

Date:17/12/2024

Student Numbers: JueLin Liu, 24036199 Yingxi Zhou, 23225727 Yale Lu, 24068573 Yuanqing Zhang, 23157049 Kun Li

## Brief Group Reflection

| What Went Well | What Was Challenging |
| -------------- | -------------------- |
| A              | Data Collection      |
| C              | D                    |

## Priorities for Feedback

Are there any areas on which you would appreciate more detailed feedback if we're able to offer it?



{{< pagebreak >}}

# Response to Questions

See the raw file for examples of how to hide computational output as there is code hidden here.

```{python}

#GWR-Entire home/apt price and density
import pandas as pd
import geopandas as gpd
from libpysal.weights import Queen
from esda import Moran, Moran_Local
import matplotlib.pyplot as plt
from mgwr.gwr import GWR
import pyproj
import numpy as np
from sklearn.preprocessing import StandardScaler

# Read Airbnb “Entire home/apt” data
Enprice_file = r"C:/Users/asus/OneDrive - University College London/CASA0007 reading/Enprice.csv"
shapefile = r"C:/Users/asus/OneDrive - University College London/Desktop/ESRI/London_Borough_Excluding_MHW.shp"
price_by_neighbourhood = pd.read_csv(Enprice_file)
geo_data = gpd.read_file(shapefile)
geo_data = geo_data.merge(price_by_neighbourhood, left_on="NAME", right_on="neighbourhood")
geo_data['price'] = pd.to_numeric(geo_data['price'], errors='coerce')

# Draw “Entire home/apt” price map
fig, ax = plt.subplots(1, 1, figsize=(10, 10))
geo_data.plot(column='price',
              cmap='coolwarm',
              legend=True,
              linewidth=0.5,
              edgecolor='black',
              ax=ax)

ax.set_title("Airbnb “Entire home/apt” price - borough", fontsize=15)
ax.set_axis_off()
plt.show()

# price Moran's I test
weights = Queen.from_dataframe(geo_data)
weights.transform = "R"

moran = Moran(geo_data["price"], weights)
print(f"Global Moran's I: {moran.I}, p-value: {moran.p_sim}")

# Read other data（income median, population density，airbnb Entire home density）,merge all data
income_pp_file = r"C:/Users/asus/OneDrive - University College London/Desktop/social-eco data.xlsx"
income_pp_df = pd.read_excel(income_pp_file)

mean_price_file = r"C:/Users/asus/OneDrive - University College London/CASA0007 reading/merged_rental_and_density.csv"
mean_price_df = pd.read_csv(mean_price_file)

merged_data = geo_data.merge(income_pp_df, left_on="NAME", right_on="NAME", how="left")
merged_data = merged_data.merge(mean_price_df, left_on="NAME", right_on="NAME", how="left")

# Extract the latitude and longitude of the center point
merged_data['centroid'] = merged_data.geometry.centroid
merged_data['latitude'] = merged_data['centroid'].y
merged_data['longitude'] = merged_data['centroid'].x

# Set projection: OSGB36 (UK National Grid) to WGS84 (Latitude and longitude coordinate system)
projection = pyproj.Transformer.from_crs("EPSG:27700", "EPSG:4326", always_xy=True)

def convert_to_lat_lon(x, y):
    lon, lat = projection.transform(x, y)
    return lat, lon

merged_data[['latitude', 'longitude']] = merged_data.apply(
    lambda row: pd.Series(convert_to_lat_lon(row['longitude'], row['latitude'])),
    axis=1
)


# Independent and dependent variables of GWR were extracted and standardized
y = merged_data["borough_weighted_average"].values.reshape((-1, 1))
X = merged_data[["price", "Density", "income-median", "Population per hectare"]].values
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_std = scaler_X.fit_transform(X)
y_std = scaler_y.fit_transform(y)

# Execute the GWR model and view the regression results
coords = [(lat, lon) for lat, lon in zip(merged_data['latitude'], merged_data['longitude'])]
bw = 20
gwr_model = GWR(coords, y_std, X_std, bw)
gwr_results = gwr_model.fit()
gwr_model = GWR(coords, y, X, bw)
gwr_results = gwr_model.fit()
print("GWR results:", gwr_results.summary())

# Get the GWR coefficient of Airbnb “Entire home/apt” price and visualize it
gwr_coefficients = gwr_results.params[:, 1]
gwr_coefficients_abs = np.abs(gwr_coefficients)

merged_data['gwr_coefficients_abs'] = gwr_coefficients
fig, ax = plt.subplots(figsize=(12, 10))
from matplotlib.colors import LinearSegmentedColormap
import matplotlib.pyplot as plt
red_cmap = LinearSegmentedColormap.from_list("custom_red", ["#F5F8FA", "#990000"])
merged_data.plot(column='gwr_coefficients_abs',
                 ax=ax,
                 legend=True,
                 legend_kwds={'label': "Airbnb “Entire home/apt” price-GWR Coefficients",
                              'orientation': "horizontal"},
                 cmap=red_cmap,
                 edgecolor='k', linewidth=0.5)
plt.title("Airbnb “Entire home/apt” price-GWR Coefficients Visualization", fontsize=16)
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.show()

# Get the GWR coefficient of Airbnb “Entire home/apt” Density and visualize it
gwr_coefficients = gwr_results.params[:, 2]
gwr_coefficients_abs = np.abs(gwr_coefficients)
merged_data['gwr_coefficients_abs'] = gwr_coefficients
fig, ax = plt.subplots(figsize=(12, 10))
blue_cmap = LinearSegmentedColormap.from_list("custom_blue", ["#F5F8FA", "#133F7F"])
merged_data.plot(column='gwr_coefficients_abs',
                 ax=ax,
                 legend=True,
                 legend_kwds={'label': "Airbnb “Entire home/apt” Density-GWR Coefficients",
                              'orientation': "horizontal"},
                 cmap=blue_cmap,
                 edgecolor='k', linewidth=0.5)

plt.title("Airbnb “Entire home/apt” Density-GWR Coefficients Visualization", fontsize=16)
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.show()

```

## 1. Who collected the InsideAirbnb data?

::: {.duedate}

( 2 points; Answer due Week 7 )

Murray Cox is the founder and current chief data activist of Inside Airbnb. He conceived the project, compiled and analyzed the data, and built the site. A variety of collaborators and partners interested in InsideAirbnb also contributed to data updates and maintenance, for example Taylor Higgins, Michael "Ziggy" Mintz, and so on.
:::

An inline citation example: As discussed on @insideairbnb, there are many...

A parenthetical citation example: There are many ways to research Airbnb [see, for example, @insideairbnb]... 

## 2. Why did they collect the InsideAirbnb data?

::: {.duedate}

( 4 points; Answer due Week 7 )

Because they aim to provide data and advocacy about Airbnb's impact on residential communities. And they work towards a vision where communities are empowered with data and information to understand, decide and control the role of renting residential homes to tourists.

:::

```{python}
#| output: asis
print(f"One of way to embed output in the text looks like this: after cleaning, we were left with {df.shape[0]:,} rows of data.")
```

This way is also supposed to work (`{python} f"{df.shape[0]:,}" `) but I've found it less reliable.

```{python}
ax = df.host_listings_count.plot.hist(bins=50);
ax.set_xlim([0,500]);
```

## 3. How did they collect it?

::: {.duedate}

( 5 points; Answer due Week 8 )
Inside Airbnb collects its data by scraping publicly available information from Airbnb's website. This process involves extracting details such as listing descriptions, host information, availability calendars, and user reviews. The collected data is then verified, cleansed, analyzed and aggregated.
:::

## 4. How does the method of collection (Q3) impact the completeness and/or accuracy of the InsideAirbnb data? How well does it represent the process it seeks to study, and what wider issues does this raise?

::: {.duedate}

( 11 points; Answer due Week 9 )

:::

InsideAirbnb collects data by scraping publicly available Airbnb listings, a method that can introduce certain limitations. For instance, inactive or off-platform listings may be missing, leading to incomplete coverage. Scraping errors and Airbnb’s deliberate data obfuscation, hiding exact locations or limiting transparency about occupancy, can also affect data accuracy. Additionally, because listings can be deactivated, modified, or newly added between scraping sessions, the dataset may become outdated over time.

While the data provides a useful snapshot of Airbnb’s activity, it does not fully capture the complexities of host and guest interactions. This raises concerns about representation bias, as hidden transactions remain unaccounted for. Privacy issues also emerge from using personal data without explicit consent. Furthermore, relying on incomplete data could result in misleading conclusions for urban planning and policy-making.


## 5. What ethical considerations does the use of the InsideAirbnb data raise? 

::: {.duedate}

( 18 points; Answer due {{< var assess.group-date >}} )
First, informed consent and privacy issues. Inside Airbnb is obtained by scraping data from the Airbnb website. The possible problem is that hosts and Airbnb users do not know that their data is being collected, which raises transparency and autonomy issues. At the same time, the scraped data includes property addresses, personal comments, etc., which may cause harassment or privacy violations.
Second, representative bias. Airbnb listings may be concentrated in administrative areas with better geographical (such as inner London) and socioeconomic conditions, while low-income communities and underrepresented communities with fewer Airbnb listings may be ignored or marginalized. At the same time, hosts on Airbnb do not represent the general population. They usually tend to be higher-income people and do not include workers living in public housing. Conclusions based solely on Airbnb data may ignore diverse housing needs. In addition, Airbnb's search algorithm may give priority to highly rated, high-priced, and more active listings, ignoring inactive or low-rent listings, resulting in the scraped data reflecting platform bias and exaggerating market activities.

:::

## 6. With reference to the InsideAirbnb data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and the types of properties that they list suggest about the nature of Airbnb lettings in London? 

::: {.duedate}

( 15 points; Answer due {{< var assess.group-date >}} )


(3)According to the statistics of airbnb listing data in 2023, the majority of airbnb listings are "Entire home/apt", accounting for 66.8%. In addition, from the average rent distribution diagram of "Entire home/apt" housing type in Figure 1, it can be seen that there are significant differences in rent in different administrative regions. City centres such as Westminster and Kensington&Chelsea rent for up to £350 a night, while outside the city centre rates are relatively low.
:::

## 7. Drawing on your previous answers, and supporting your response with evidence (*e.g.* figures, maps, EDA/ESDA, and simple statistical analysis/models drawing on experience from, e.g., CASA0007), how *could* the InsideAirbnb data set be used to inform the regulation of Short-Term Lets (STL) in London? 

::: {.duedate}

( 45 points; Answer due {{< var assess.group-date >}} )
(3) Analysis of the spatial impact of Airbnb's "Entire home/apt" listing density and price
To assess the spatial impact of Airbnb's "Entire home/apt" listing density and price on monthly rent levels in different London boroughs. This report uses a geographically weighted regression (GWR) model, a spatial statistical method that takes into account the effects of geographic location on the regression coefficients to provide a more accurate estimate of regional differences. Compared with traditional global regression models, GWR models can reveal spatial differences in the relationship between dependent and independent variables in different regions, thus providing region-specific insights for policy makers. In order to fully understand the market dynamics, the model also includes population density and mean income as control variables to reveal the determinants of rent levels in different regions.
As shown in Figure 2 and Figure 3，we found that the impact of Airbnb's "Entire home/apt" type of housing density and price on rents is spatially significant, reflecting differences in economic structure, housing demand and market competition in different parts of London. Specifically, the regression coefficients of Airbnb listings density and housing prices show significant differences in space. For example, the regression coefficient of Airbnb listings density is higher in some regions, such as the downtown and northwest, showing a strong positive effect, while the effect is smaller or even negative in other regions, which may be related to the saturation of housing supply in the region or the lack of demand in the rental market. On the other hand, Airbnb prices have a greater impact on rental levels and a higher regression coefficient in the downtown and southern regions, while the effect is gradually weakened in the northern region, which may reflect the intense market competition and high short-term rental price sensitivity in the southern region.
Based on the results of GWR analysis, the government can adopt regionally differentiated Airbnb regulatory policies. In areas where the density of Airbnb “Entire home/apt” listings has a significant impact on rents, such as downtown and northwest China, the government can limit the number of listings and set the limit of short-term rental days to ease the efficient response of the short-term rental market to long-term housing rents and protect the housing affordability of residents. For the downtown and southern areas where Airbnb “Entire home/apt” prices have a significant impact on rents, the government can balance housing supply and demand through tax policies, market guidance and other means to avoid further rent increases. In addition, for areas with less impact or market sensitivity, appropriate relaxation of regulatory policies to promote the flexible operation of the market, so as to achieve accurate and efficient regulation of the housing market. This kind of policy making based on local conditions not only helps to stabilize the rent level, but also alleviates the uneven development of the housing market between different regions.

:::

## Sustainable Authorship Tools

Using the Terminal in Docker, you compile the Quarto report using `quarto render <group_submission_file>.qmd`.

Your QMD file should automatically download your BibTeX and CLS files and any other required files. If this is done right after library loading then the entire report should output successfully.

Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style="font-family:Sans-Serif;">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). 

## References
